---
title: "snRNAseq_Doublet_SetThreshold_v1"
author: "Katie Prater and Kevin Green"
date: "5/26/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
Sys.setenv(PATH = "/home/src/python-3.8.1/bin:$PATH:")
library(stringr)
```

#Jayadev Lab snRNAseq Pipeline

##Doublet Detection with set thresholds to clean up snRNAseq data

### R Markdown note:
This is an R Markdown document. When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document.

## Set samples that need to be rerun and the doublet thresholds that you want. *** You DO need to edit this!****
```{r Set_Thresholds}
#Tell the code which samples to rerun:
rerun_samples<-c("s6802_PU1", "s6815_PU1")

#Give the appropriate threshold for Scrublet to use for each sample in the same order you wrote them above.
#**Note that you cannot run just one sample here. If you are running just one, please put a 0 in the second slot.
thresholds<-c(0.42, 0.50)
```

##First ensure you have the variables and directories set up as needed for the project. This should be identical to the code chunk you edited the first time. ***You DO need to edit this code chunk! ***
```{r Directory_setup}
#Document your code:
print("This is when this code was started:")
print(Sys.time())

#Define your project folder:
#projdir <- "path_to_my_project_folder_name"
projdir <- "~/jayadev/PU.1/exp_2-25-20/Full_sequence/code/pu1_only/"

#Name of the Rdata file to load in:
start_data <- "decon_split_matrices_ws_pu1_only.rdata"


#__________________Do not edit below this line______________________________

#Load the thresholded Seurat object saved before
data_loc<-file.path(projdir, "code", start_data, fsep = "/")
print(paste('Loading data', start_data, sep = " "))
load(start_data)

#Create an array of the redo samples
redo_names <- rep(NA, length(rerun_samples))
for (sample in 1:length(rerun_samples)) {
  redo_names[[sample]] <- paste0('tcm_', rerun_samples[sample])
}

```

## Load Libraries needed for code
```{r Load_Libraries, warning=FALSE}
print('Loading Libraries Seurat, ggplot2, Matrix, and filesstrings.')
  library(Seurat)
  library(ggplot2)
  library(Matrix)
  library(filesstrings)
```

## Redo doublet detection using Scrublet and the thresholds that we set before based on the histograms:
### Scrublet is a python package, so we are using a python code chunk here.

```{python Redo_Scrublet_Detection}
#Document which version of Python you are using
import sys
print("You are using Python {}.{}.".format(sys.version_info.major,  sys.version_info.minor))

# Setup Python with the libraries we want to use
import scrublet as scr #(for R: scr<-import('scrublet'))
import scipy.io
import matplotlib.pyplot as plt
import numpy as np
import os
import csv

#Run Scrublet on all samples
samples = list(r.redo_names)
#for sample in samples:
for sample_index, sample in enumerate(samples):

    #Read in the transposed counts matrix to scrublet and python
    #Matrix needs to be cells as rows and genes as columns
    input_dir = r.projdir
    counts_matrix = r[sample]
    genes = r.genes

    #Print to screen the size of the matrix so we can see the number of genes
    print('Counts matrix shape: {} rows, {} columns'.format(counts_matrix.shape[0], counts_matrix.shape[1]))
    print('Number of genes in gene list: {}'.format(len(genes)))

    #Initialize the scrublet object
    scrub = scr.Scrublet(counts_matrix, expected_doublet_rate=0.12)
    #Expected doublet rate is 0.8% per 1600 cells based on 10X Chromium documentation.
    #Kevin loads ~24000 nuclei, so we expect our doublet rate to be about 12%
    print('Expected Doublet Rate is: 0.12')

    #Run default Scrublet pipeline
    print('Running default Scrublet pipeline')
    import time
    t = time.localtime()
    current_time = time.strftime("%H:%M:%S", t)
    print(current_time)
    doublet_scores, predicted_doublets = scrub.scrub_doublets(
        min_counts=2, 
        min_cells=3,
        min_gene_variability_pctl=85,
        n_prin_comps=30
    )

    #The threshold should be detected at the minimum between the two simulated modes of doublets. This was not accurately detected for these samples, so we are redoing their threshold.
    print('Running {} with threshold {}.'.format(sample, r.thresholds[sample_index]))
    threshold_predicted_doublets = scrub.call_doublets(threshold=r.thresholds[sample_index])
    
    #Write the doublet_scores and predicted_doublets to a csv file for each sample
    #Print to screen the size of the matrix so we can confirm we are writing all the info
    print('Doublet scores shape: {} rows'.format(doublet_scores.shape[0])) 
    print('Predicted Doublets shape: {} rows'.format(predicted_doublets.shape[0]))
    with open(sample[4:]+'_redo_decon_doublet_scores.csv', 'w', newline='\n') as csvfile:
        samplewriter = csv.writer(
            csvfile,
            delimiter=',',
            quotechar='|',
           quoting=csv.QUOTE_MINIMAL
        )
        samplewriter.writerow([
            'doublet_scores',
            'predicted_doublets'
        ])
        for doublet_index, doublet_score in enumerate(doublet_scores):
            samplewriter.writerow([
                doublet_score,
                threshold_predicted_doublets[doublet_index]
            ])
 
    #Visualize the data and the threshold Scrublet chose for doublets
    scrub.plot_histogram();
    plt.suptitle(sample[4:])
    plt.show()
    plt.savefig(sample[4:] + '_redo_decon_doublet_histo.png', transparent=True)

    #Run UMAP to visualize doublets in clusters
    print('Running UMAP...')
    scrub.set_embedding('UMAP', scr.get_umap(scrub.manifold_obs_, 10, min_dist=0.3))
    print('Done.')

    #Plot UMAPS. Doublets should cluster together.
    scrub.plot_embedding('UMAP', order_points=True);
    plt.suptitle(sample[4:])
    plt.show()
    plt.savefig(sample[4:] + '_redo_decon_doublet_umaps.png', transparent=True)
```

##Scrublet has been rerun, now we put all the generated data in the output folder.
```{r Cleanup_Files}
#Move the histograms and umap images to the output folder.
pngs<- Sys.glob("*.png")
move_files(pngs, outpath, overwrite = TRUE)

#Move the csv files to the output folder
csvs<- Sys.glob("*scores.csv")
move_files(csvs, outpath, overwrite = TRUE)

options(width = 60)
print(paste('Scrublet data and plots stored in:', outpath, sep = ' '))
```
