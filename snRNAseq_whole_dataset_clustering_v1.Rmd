---
title: "snRNAseq_clusters_v1"
author: "Katie Prater and Kevin Green"
date: "6/24/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(Seurat)
library(Matrix)
library(ggplot2)
library(stringr)
library(dplyr)
library(filesstrings)
```
#Jayadev Lab snRNAseq Pipeline

##Removal of unwanted effects for cleanup of data

### R Markdown note:
This is an R Markdown document. When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document.

##First ensure you have the variables and directories set up as needed for the project. This should be identical to the code chunk you edited the first time. ***You DO need to edit this code chunk! ***
```{r Setup}
#Define your project folder:
#projdir <- "path_to_my_project_folder_name"
projdir <- "~/jayadev/PU.1/exp_2-25-20/Full_sequence/"

#Previous data file name: (give the name for the appopriate RDS/Rdata file)
prev_data <- "decon_scrubbed_thresholded_norm_all13remaining_ws.RData"

#Reset directories for PU.1 dataset. 
#This should be removed from final version.
outdir <- "output"
plotspath <- file.path(projdir, outdir, "qc_plots", fsep = "/")


#Does the data need correction? (e.g. batch, mitochondrial genes, etc)
#Enter TRUE or FALSE
regression <- TRUE

#Does the data need variable genes identified?
#Enter TRUE or FALSE
variable_genes <- TRUE

#Create a list of variables from which to remove unwanted variation.
#e.g. c("percent.mito", "nCount_RNA", "Library.Batch", "PMI")
unwanted <- c("percent.mito", "nCount_RNA", "Library.Batch", "PMI", "Norm.Batch")

#Define the number of genes you want after variable gene detection:
nfeatures = 5000


#__________________**DO NOT EDIT BELOW THIS LINE**___________________________
```

## Load in the data you specified:
```{r Load_Data}
#Document your code:
print("This is when this code was started:")
print(Sys.time())

#Make the path for the previous data file and load it into the R environment
prev_data_path<-file.path(projdir, "code", prev_data, fsep = "/")
print(paste("Loading the previous data file:", prev_data_path, sep = " "))
#ss_data <- readRDS(prev_data_path)
load(prev_data_path)
```

```{r Set_Directories}
#Ensure paths are set for code:
outpath <- file.path(projdir, outdir, fsep = "/")
if (file.exists(outpath))
    {cat("Output directory path works!")} else 
    {cat("Output directory does not exist - creating")
    dir.create(outpath)}

#Number of participants/samples to process:
numsubs <- length(samples)
print(paste("Processing", numsubs, "samples", sep = " "))

#Documentation:
print("This is where the project is:")
print(projdir)
print("This is where the sample files are:")
print(sample_dir)
print("This is where the data files will be saved:")
print(outpath)

```

## If your normalization only saved the variable genes, you do not need to find them again. If you saved all genes, you will need to identify the variable genes. We default to finding the top 5000 variable genes.
```{r PCA}

#Find variable genes if not done already during normalization.
if (variable_genes) {
  print("Finding the top 5000 variable genes.")
  ss_data_norm <- FindVariableFeatures(ss_data_norm,
                                    assay = assay,
                                    nfeatures = nfeatures)
}

#Regress out unwanted variation
if (regression) {
  # Read in the meta data csv file
  ss_csv <- "samples_project_metadata_13.csv"
  meta_data <- read.csv(ss_csv, header = TRUE)

  # Split object by sample
  ss_data_norm <- SplitObject(ss_data_norm,
                              split.by = "orig.ident")
  
  # Add MetaData to object
  for (sample in 1:length(ss_data_norm)) {
    for (variable in 1:ncol(meta_data)) {
      var_name <- names(meta_data[variable])
      ss_data_norm[[sample]][[var_name]] <- meta_data[sample, variable]
    }
  }
  
  # Recombine samples after adding meta data
  ss_data_norm <- merge(ss_data_norm[[1]], c(ss_data_norm[[2]], 
                            ss_data_norm[[3]], ss_data_norm[[4]], 
                            ss_data_norm[[5]], ss_data_norm[[6]], 
                            ss_data_norm[[7]], ss_data_norm[[8]],
                            ss_data_norm[[9]], ss_data_norm[[10]], 
                            ss_data_norm[[11]], ss_data_norm[[12]], 
                            ss_data_norm[[13]]
                            #, ss_data_norm[[14]], 
                            #ss_data_norm[[15]], ss_data_norm[[16]], 
                            #ss_data_norm[[17]], ss_data_norm[[18]], 
                            #ss_data_norm[[19]]
                            ))
  
  ss_data_norm[["percent.mito"]] <- PercentageFeatureSet(object = ss_data_norm, pattern = "^MT-")
  
  # Remove objects that are no longer needed
  rm(var_name, meta_data)
    
  ss_data_norm <- ScaleData(ss_data_norm,
                            vars.to.regress = unwanted,
                            do.scale = FALSE,
                            do.center = FALSE)
}

#Run PCA
print("Running PCA")
print(Sys.time())
ss_data_norm <- RunPCA(ss_data_norm, 
                  assay = assay, 
                  features = VariableFeatures(ss_data_norm), 
                  npcs = 20)

#Determine the number of PCs required to obtain a change in standard deviation less than 0.1.
PCs <-Stdev(ss_data_norm@reductions$"pca")
PCs <- min((which(diff(PCs) > -.1)))
print(paste("The recommended number of prinicple components is:", PCs, sep = " "))

#Generate an elbow plot for the PCA
plot1 <- ElbowPlot(ss_data_norm)
png(paste(plotspath, "PC_elbow_plot_combined_data.png", sep = "/"))
print(plot1)
dev.off()

```

## Generate UMAP for dataset
```{r Cluster}
#Find Nearest Neighbors
print("Finding nearest neighbors")
print(Sys.time())
ss_data_norm <- FindNeighbors(ss_data_norm,
                           dims = 1:PCs,
                           assay = assay,
                           verbose = TRUE)

#Find clusters
print("Finding clusters")
print(Sys.time())
ss_data_norm <- FindClusters(ss_data_norm,
                         assay = assay,
                         resolution = c(0.4, 0.6, 0.8, 1.0))

resolutions <- c("SCT_snn_res.0.4", "SCT_snn_res.0.6", "SCT_snn_res.0.8", "SCT_snn_res.1")

umap_pngs <- c("UMAP_0.4", "UMAP_0.6", "UMAP_0.8", "UMAP_1.0")

#Identify clusters:
print("Making UMAP clusters")
print(Sys.time())
ss_data_norm <- RunUMAP(ss_data_norm,
                         assay = assay,
                         dims = 1:PCs)

#Plot clusters
plot_clusters <- function(data, resolutions, label) {
  for (resolution in 1:length(resolutions)) {
    plot2 <- DimPlot(object = data,
                     reduction = "umap",
                     group.by = resolutions[[resolution]],
                     pt.size = 2,
                     label = TRUE,
                     label.size = 10)
    png(paste0(plotspath, "/", proj, "_",
                umap_pngs[[resolution]], "_",
                label, suffix, ".png", sep = ""), 800, 800)
    print(plot2)
    dev.off()
  }
}

plot_clusters(ss_data_norm,resolutions, "postQC")
```

## Save the data files.
```{r Save_Files}
rm(plot1)
#Save workspace image if needed to revisit
save.image(file = paste0("ss_data_norm_clustered_ws", suffix, ".rdata"), compress = TRUE)

```

