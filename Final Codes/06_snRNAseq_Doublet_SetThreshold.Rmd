---
title: "snRNAseq_Doublet_SetThreshold_v1"
author: "Katie Prater and Kevin Green"
date: "5/26/2020"
output:
  html_document:
    df_print: paged
params:
  container: ""
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
use_condaenv("/gscratch/jayadevlab/files/software/conda/envs/miniconda_setup")
library(Seurat)
library(ggplot2)
library(Matrix)
library(filesstrings)
```

# Jayadev Lab snRNAseq Pipeline

## Doublet Detection with set thresholds to clean up snRNAseq data

### R Markdown note:
This is an R Markdown document. When you click the **Knit** button a document
will be generated that includes both content as well as the output of any
embedded R code chunks within the document.

## Set samples that need to be rerun and the doublet thresholds that you want.
# You MUST edit this for your dataset to run properly!!!!
```{r Directory_setup}
# Name of the Rdata file to load in:
start_data <- "decon_split_matrices_ws_20210331.rdata"

# Tell the code which samples to rerun:
rerun_samples <- c("s1441_PU1", "s6672_PU1", "s6684_PU1", "s6686_PU_1", "s6706_PU1", "s6719_PU_1", "s6729_PU1", "s6731_PU1", "s6734_PU1", "s6761_PU1", "s6768_PU1", "s6776_PU_1", "s6802_PU1", "s6815_PU1", "s6868_PU1", "s6870_PU_1", "s6992_PU_1", "s7017_PU_1", "s7064_PU_1", "s7065_PU_1")

# Give the appropriate threshold for Scrublet to use for each sample in the same
# order you wrote them above.
# **Note that you cannot run just one sample here. If you are running just one,
# please put a 0 in the second slot.
thresholds <- c(0.46, 0.42, 0.45, 0.49, 0.35, 0.43, 0.39, 0.45, 0.42, 0.40, 0.51, 0.41, 0.44, 0.50, 0.51, 0.50, 0.45, 0.40, 0.42, 0.40)

#__________________Do not edit below this line______________________________
```

### Load in the data you specified:
```{r Load_Data}
# Document your code:
print(paste("This is when this code was started:", Sys.time()))

# Print which container is being used
if (identical(params$container, "")) {
  stop("The container number must be documented before rendering.
       params= list(container = ###)")
}
print(paste("Container number", params$container, "was used"))

# Load the decontaminated Seurat object saved before
print(paste('Loading data', start_data, sep = " "))
load(paste0("../data/r_files/", start_data))

# Print container package versions, if changed from previous
if (!identical(params$container, prev_container)) {
  print("This code was run using:")
  print(sessionInfo())
  prev_container <- params$container
}
rm(params)
Sys.umask(mode = "000")
```

```{r Set_Directories}
# Number of participants/samples to process:
numsubs <- length(samples)
print(paste("Processing", numsubs, "samples", sep = " "))

# Documentation:
print(paste("This is where the project is:", normalizePath(projdir)))
print(paste("This is where the sample files are:", normalizePath(sample_dir)))
print(paste("This is where the data files will be saved:",
             normalizePath(outpath)))
```

```{r Redo_array}
# Create an array of the redo samples
redo_names <- rep(NA, length(rerun_samples))
for (sample in 1:length(rerun_samples)) {
  redo_names[[sample]] <- paste0('tcm_', rerun_samples[sample])
}
```

### Redo doublet detection using Scrublet and the thresholds that we set before
### based on the histograms:
### Scrublet is a python package, so we are using a python code chunk here.
```{python Redo_Scrublet_Detection}
# Document which version of Python you are using
import sys
print("You are using Python {}.{}.".format(sys.version_info.major,  sys.version_info.minor))

# Setup Python with the libraries we want to use
import scrublet as scr #(for R: scr<-import('scrublet'))
import scipy.io
import matplotlib.pyplot as plt
import numpy as np
import os
import csv

# Run Scrublet on all samples
samples = list(r.redo_names)
# for sample in samples:
for sample_index, sample in enumerate(samples):

    # Read in the transposed counts matrix to scrublet and python
    # Matrix needs to be cells as rows and genes as columns
    input_dir = r.projdir
    counts_matrix = r[sample]
    genes = r.genes

    # Print to screen the size of the matrix so we can see the number of genes
    print('Counts matrix shape: {} rows, {} columns'.format(counts_matrix.shape[0], counts_matrix.shape[1]))
    print('Number of genes in gene list: {}'.format(len(genes)))

    # Initialize the scrublet object
    scrub = scr.Scrublet(counts_matrix, expected_doublet_rate=0.12)
    # Expected doublet rate is 0.8% per 1600 cells based on 10X Chromium
    # documentation. Kevin loads ~24000 nuclei, so we expect our doublet rate to
    # be about 12%
    print('Expected Doublet Rate is: 0.12')

    # Run default Scrublet pipeline
    print('Running default Scrublet pipeline')
    import time
    t = time.localtime()
    current_time = time.strftime("%H:%M:%S", t)
    print(current_time)
    doublet_scores, predicted_doublets = scrub.scrub_doublets(
        min_counts=2, 
        min_cells=3,
        min_gene_variability_pctl=85,
        n_prin_comps=30
    )

    # The threshold should be detected at the minimum between the two simulated
    # modes of doublets. This was not accurately detected for these samples, so
    # we are redoing their threshold.
    print('Running {} with threshold {}.'.format(sample, r.thresholds[sample_index]))
    threshold_predicted_doublets = scrub.call_doublets(threshold=r.thresholds[sample_index])
    
    # Write the doublet_scores and predicted_doublets to a csv file for each
    # sample. Print to screen the size of the matrix so we can confirm we are
    # writing all the info
    print('Doublet scores shape: {} rows'.format(doublet_scores.shape[0])) 
    print('Predicted Doublets shape: {} rows'.format(predicted_doublets.shape[0]))
    with open(sample[4:]+'_redo_decon_doublet_scores.csv', 'w', newline='\n') as csvfile:
        samplewriter = csv.writer(
            csvfile,
            delimiter=',',
            quotechar='|',
           quoting=csv.QUOTE_MINIMAL
        )
        samplewriter.writerow([
            'doublet_scores',
            'predicted_doublets'
        ])
        for doublet_index, doublet_score in enumerate(doublet_scores):
            samplewriter.writerow([
                doublet_score,
                threshold_predicted_doublets[doublet_index]
            ])
 
    # Visualize the data and the threshold Scrublet chose for doublets
    scrub.plot_histogram();
    plt.suptitle(sample[4:])
    plt.show()
    plt.savefig(sample[4:] + '_redo_decon_doublet_histo.png', transparent=True)

    # Run UMAP to visualize doublets in clusters
    print('Running UMAP...')
    scrub.set_embedding('UMAP', scr.get_umap(scrub.manifold_obs_, 10, min_dist=0.3))
    print('Done.')

    # Plot UMAPS. Doublets should cluster together.
    scrub.plot_embedding('UMAP', order_points=True);
    plt.suptitle(sample[4:])
    plt.show()
    plt.savefig(sample[4:] + '_redo_decon_doublet_umaps.png', transparent=True)
```

### Scrublet has been rerun, now we put all the generated data in the output folder.
```{r Cleanup_Files}
# Move the histograms and umap images to the output folder.
pngs<- Sys.glob("*.png")
move_files(pngs, doublet_path, overwrite = TRUE)

# Move the csv files to the output folder
csvs<- Sys.glob("*scores.csv")
move_files(csvs, doublet_path, overwrite = TRUE)

options(width = 60)
print(paste('Scrublet data and plots stored in:', doublet_path, sep = ' '))
```
