---
title: "snRNAseq_create_UMAPs"
author: "Kevin Green"
date: "6/1/2020"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, cache=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
Sys.setenv(PATH="/acct/guest/.TinyTeX/bin:$PATH:")
library(tinytex)
library(Seurat)
library(monocle3) 
library(Matrix)
library(ggplot2)
library(foreach)
library(doParallel)
library(stringr)
library(parallel)
```

# Jayadev Lab RNAseq Data Processing Pipeline

## Define your project folders, filenames, and variables of interest.
# You MUST edit this for your dataset to run properly!!!!
```{r 'Project_Information', echo=TRUE}
#Document your code:
print("This is when this code was run:")
print(Sys.time())

# Provide number of variable genes to find. 
# Use 5000 for analysis, use 2000 for faster clustering prior to SoupX analysis.
nfeatures <- 2000

#Create a list of variables from which to remove unwanted variation.
#e.g. c("percent.mito", "nCount_RNA", "Library.Batch", "PMI")
unwanted <- c("percent.mito", "nCount_RNA")

# Read in data from which UMAPs will be created
load("normalized_pu1_only_test.rdata")

# Set the assay where data was saved during normalization ("RNA" or "SCT")
assay <- "SCT"

```

## Run PCA on samples individually
```{r Find_var_PCs}
#ss_data_normalized <- readRDS("seurat_ss_data_normalized_remaining.rds")

#Split the Seurat object back into its separate participant pieces
#so that we can run the cleanup steps on each individual.
ss_data_split <- SplitObject(ss_data_filtered,
                             split.by = "orig.ident")

#Remove files that are no longer needed
rm(ss_data_filtered)

# Set the number of cores to be used in parallel. Use a max of 10 on Orca
cores <- detectCores()
paste("Available cores = ", cores)
if (numsubs < 8) {
cores <- numsubs
} else {
  cores <- 8
}
paste("Cores used = ", cores)
registerDoParallel(cores = cores)

#Find the top variable genes for each sample
if (identical(ss_data_split[[1]]@assays$RNA@var.features, character(0))) {
  find_variable <- function(data) {
    FindVariableFeatures(data,
                         assay = assay,
                         nfeatures = nfeatures)
  }
  ss_data_split <- mclapply(ss_data_split, find_variable, mc.cores = cores)
}

#Run the scale data function to remove unwanted variation
#This does not scale the data
for (file in 1:length(ss_data_split)) {
  print(paste("Regressing out unwanted variation for sample:", names[file]))
  ss_data_split[[file]] <- ScaleData(ss_data_split[[file]],
            vars.to.regress = unwanted,
            do.scale = FALSE,
            do.center = FALSE,
            verbose = FALSE)
}
# scale_data <- function(data) {
#   #print(paste("Finding variable genes for sample:", names[file]))
#   ScaleData(data,
#             vars.to.regress = unwanted,
#             do.scale = FALSE,
#             do.center = FALSE)
# }
# ss_data_split <- mclapply(ss_data_split, scale_data, mc.cores = cores)

rm(nfeatures, unwanted)

#Run PCA for each sample
for (file in 1:length(ss_data_split)) {
  print(paste("Running PCA for sample:", names[file]))
  ss_data_split[[file]] <- RunPCA(ss_data_split[[file]],
         assay = assay,
         npcs = 20,
         verbose = FALSE)
}
# run_PCA <- function(data) {
#   #print(paste("Running PCA for sample:", names[file]))
#   RunPCA(data,
#          assay = assay,
#          features = VariableFeatures(data),
#          npcs = 20)
# }
# ss_data_split <- mclapply(ss_data_split, run_PCA, mc.cores = cores)

#Create an empty vector to which the minimum number of PCs will
#be added
PCs <- rep(NA, length(ss_data_split))

#Determine the minimum number of PCs required to obtain a change in 
#standard deviation of < 0.1. A maximum of 15 PCs is set.
for (file in 1:length(ss_data_split)) {
  print(paste("Determining the PCs required for sample:", names[file]))
  pcs <- Stdev(ss_data_split[[file]]@reductions$"pca")
  lowest <- min(which(pcs < 1.75))
  pcs <- min(which(diff(pcs[lowest:length(pcs)]) > -.1)) + lowest
  PCs[[file]] <- pcs
}

# Changes the maximum PCs to 15 and prints the number of PCs used for each sample.
for (num in 1:length(ss_data_split)) {
  if (PCs[num] > 15) {
    print(paste("Warning:", names[num], "has", PCs[num], "PCs. Changing to 15 PCs."));
    PCs[num] <- 15;
  }
  print(paste("The number of PCs used for", names[num], "is", PCs[num]));
}

#Print elbow plots for each sample.
plot_pcs <- function(data, label) {
  for (file in 1:length(data)) {
    plot10 <- ElbowPlot(data[[file]])
    png(paste(plotspath, "/", names[[file]], label,
              "_PC_elbow_plot.png", sep = ""))
      print(plot10)
    dev.off()
  }
}

plot_pcs(ss_data_split, suffix)

#Reset sample names because foreach does not return names
# for (file in 1:length(ss_data_split)) {
#   names(ss_data_split)[file] <- names[[file]]
# }

#Save workspace image if needed to revisit
#save.image(file = paste0("UMAP_ws", suffix, ".rdata"), compress = TRUE)
```

#Cluster cells using UMAP
```{r}

#Find nearest neighbors
find_neighbors <- function(data) {
  foreach (file = 1:length(data)) %do% {
    print(paste("Finding nearest neighobrs for sample:", names[file]))
    FindNeighbors(data[[file]],
                  dims = 1:PCs[[file]],
                  verbose = TRUE)
  }
}

ss_data_split <- find_neighbors(ss_data_split)

#Store the number of variables in meta data
nVariables <- ncol(ss_data_split[[1]]@meta.data)

#Find clusters based on resolution of nearest neighbors
find_clusters <- function(data) {
  foreach (file = 1:length(data)) %dopar% {
    FindClusters(data[[file]],
                 resolution = c(0.4, 0.6, 0.8, 1.0))
  }
}

ss_data_split <- find_clusters(ss_data_split)

#ss_data_split <- mclapply(ss_data_split, find_clusters, mc.cores = cores)

resolutions <- c(paste0(assay, "_snn_res.0.4"), 
                 paste0(assay, "_snn_res.0.6"), 
                 paste0(assay, "_snn_res.0.8"), 
                 paste0(assay, "_snn_res.1"))

umap_pngs <- c("UMAP_0.4", "UMAP_0.6", "UMAP_0.8", "UMAP_1.0")
                    
# Assign identity of clusters
identify_clusters <- function(data) {
  foreach(file = 1:length(data)) %do% {
    print(paste("Applying cluster identity for sample:", names[file]))
    RunUMAP(data[[file]],
            dims = 1:PCs[[file]])
    }
}

ss_data_split <- identify_clusters(ss_data_split)

plot_clusters <- function(data, resolutions, number) {
  for(file in 1:length(data)) {
    for (resolution in 1:length(resolutions)) {
      plot11 <- DimPlot(object = data[[file]],
                        reduction = "umap",
                        group.by = resolutions[[resolution]],
                        pt.size = 2)
      png(paste(plotspath, "/", names[[file]], "_",
                umap_pngs[[resolution]], "_",
                number, suffix, ".png", sep = ""), 800, 800)
        print(plot11)
      dev.off()
    }
  }
}

plot_clusters(ss_data_split, resolutions, "1")

#Reset sample names because foreach does not return names
for (file in 1:length(ss_data_split)) {
  names(ss_data_split)[file] <- names[[file]]
}

#Save workspace image if needed to revisit
save.image(file = paste0("UMAP_ws", suffix, ".rdata"), compress = TRUE)
```
