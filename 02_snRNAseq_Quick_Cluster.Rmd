---
title: "snRNAseq_AmbRNA_Removal"
author: "Kevin Green"
date: "7/8/2020"
output: pdf_document
---

```{r setup, cache=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(Seurat)
library(Matrix)
library(ggplot2)
library(foreach)
library(doParallel)
library(stringr)
library(parallel)
library(scran)
library(scater)
```

# Jayadev Lab RNAseq Data Processing Pipeline

## Define your project folders, filenames, and variables of interest.
# You MUST edit this for your dataset to run properly!!!!
```{r 'Project_Information', echo=TRUE}
#Document your code:
print("This is when this code was run:")
print(Sys.time())

#Load image from snRNAseq_QC_code workspace with ss_data_split object
print("Loading thresholding_pu1_only.rdata")
load("thresholded_pu1_only.rdata")

#Set sample type (i.e. nuclei, pbmcs, organoid or other)
sample_type <- "nuclei"

#Do you want to downsample the dat for testing purposes
#Enter TRUE or FALSE
downsample <- FALSE

# Create variable for qc_plots directory
plotspath <- file.path(projdir, outdir, "qc_plots", fsep = "/")

# Change suffix if needed
suffix <- "_pu1_only"

```

```{r QC_Plots}
# #QC metric histograms colored by sample with threshold lines plotted
 plot7 <-  ggplot(ss_data@meta.data,
                  aes(color=ss_data@meta.data$orig.ident,
                      x=nCount_RNA,
                      fill= ss_data@meta.data$orig.ident)) + 
   geom_density(alpha = 0.2) + 
   scale_x_log10() + 
   theme_classic() +
   xlab("Number of copies/gene") +
   ylab("Frequency") +
   geom_vline(xintercept = 350) ##Edit this value for your threshold of choice

plot8 <-  ggplot(ss_data@meta.data,
                 aes(color=ss_data@meta.data$orig.ident,
                     x=percent.mito,
                     fill= ss_data@meta.data$orig.ident)) +
  geom_density(alpha = 0.2) +
  scale_x_log10() +
  theme_classic() +
  xlab("% Mitochondrial Genes") +
  ylab("Frequency") +
  geom_vline(xintercept = 2.0) ##Edit this value for your threshold of choice

 plot9 <-  ggplot(ss_data@meta.data,
                  aes(color=ss_data@meta.data$orig.ident,
                      x=nFeature_RNA,
                      fill= ss_data@meta.data$orig.ident)) + 
   geom_density(alpha = 0.2) + 
   theme_classic() +
   scale_x_log10() +
   xlab("Number of genes/cell") +
   ylab("Frequency") +
   geom_vline(xintercept = 350) ##Edit this value for your threshold of choice
 
#Save the plots
png(paste0(plotspath, "/QC_feature_histograms_by_sample", suffix, ".png"),
    1800, 900)
CombinePlots(plots = list(plot7,plot8,plot9))
dev.off()
```

## Threshold the data based on the above QC thresholds that you set.
```{r Threshold_data}
###### You MUST modify these thresholds for your dataset. ########
ss_data_filtered <- subset(x = ss_data,
                           subset = nFeature_RNA >= 350 &
                             nCount_RNA >= 350 &
                             percent.mito < 2.0)

rm(ss_data, list = setdiff(ls(pattern = "^plot"), "plotspath"))

```

```{r}
########### Do not edit below this line ###########

#Generate paths to data directories where barcodes.tsv.gz, features.tsv.gz and matrix.mtx.gz are located 
#samples_filenames <- paste(samples, filenames, sep="_", collapse = NULL)
samples_path <- file.path(sample_dir, samples, fsep="")

#Check if output directory exists or needs to be created.
outpath <- file.path(projdir, outdir, fsep = "/")
if (file.exists(outpath))
    {cat("Output directory path works!")} else 
    {cat("Output directory does not exist - creating")
    dir.create(outpath)}
```

```{r Downsample}

if(downsample) {
  ss_data_filtered <- subset(ss_data_filtered,
                       ident = unique(ss_data_filtered@meta.data[["orig.ident"]]),
                       downsample = 300)
}

#Save the seurat objects after thresholding.
# if(!downsample) {
#   saveRDS(ss_data_filtered, file = paste0("seurat_ss_data_thresholded", suffix, ".rds"))
# }
```

```{r Create_clusters}
# Set the number of cores to be used in parallel. Use a max of 4 on Orca
cores <- detectCores()
paste("Available cores = ", cores)
if (numsubs < 4) {
cores <- numsubs
} else {
  cores <- 4
}
paste("Cores used = ", cores)
registerDoParallel(cores = cores)

#Split the Seurat object back into its separate participant pieces
#so that we can run the cleanup steps on each individual.
ss_data_split <- SplitObject(ss_data_filtered,
                             split.by = "orig.ident")

#Remove files that are no longer needed
rm(ss_data_filtered)

#Create object to hold cluster information
clusters <- rep(NA, length(ss_data_split))

#create a function to create cluster information using Scran
create_clusters <- function(data) {
  #name <- str_sub(data@meta.data[["orig.ident"]][[1]], 1, -23)
  data <- as.SingleCellExperiment(data)
  data$clusters <- as.data.frame(quickCluster(data, method="igraph", use.ranks=FALSE))
  data <- runUMAP(data)
}
system.time(clusters <- mclapply(ss_data_split, create_clusters, mc.cores = cores
                   ))
```

```{r Save Data}

#Save workspace image if needed to revisit
save.image(file = paste0("cluster_ws", suffix, ".rdata"), compress = TRUE)
```
